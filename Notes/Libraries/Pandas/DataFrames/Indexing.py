# Indexing DataFrames

# Indices can be either autogenerated, or they can be set explicitly. Another option to setting an index is to use the set_index() function. This function takes a list of columns and promotes those columns to an index.

import pandas as pd

df = pd.read_csv("/home/aspphem/Desktop/CSV/Admission_Predict.csv", index_col=0)

print(df.head())

# Let's say we don't want to index the DataFrame by serial numbers, but instead by the chance of admit. Let's preserve the serial number into a new column. We can do this using the indexing operator on the string that has the column label. Then we can use the set_index to set index of the column to chance of admit.

# Copy the indexed data into its own column
df['Serial Number'] = df.index

# Set the index to another column
df = df.set_index('Chance of Admit ')
print(df.head())

# We can get rid of the index completely by calling the function reset_index(). This promotes the index into a column and creates a default numbered index.

df = df.reset_index()
print(df.head())

# Multi-level indexing -- similar to composite keys in relational database systems. To create a multi-level index we simply call set index and give it a list of columns that we are interested in promoting to an index.

df = pd.read_csv("/home/aspphem/Desktop/CSV/census.csv")
print(df.head())

# If we want to see a list of all the unique values in a given column we use the unique() function on the DataFrame. This is similar to the SQL distinct operator.

print(df['SUMLEV'].unique())

# There are only two different values; 40 and 50.

# Let's exclude all of the rows that are summaries at the state level and just keep the county data.

df = df[df['SUMLEV'] == 50]
print(df.head())

# Let's reduce the data that we are going to look at to just the total population estimates and the total number of births.

# We can do this by creating a list of column names that we want to keep then project those and assign the resulting DataFrame to our df variable.

columns = ['STNAME', 'CTYNAME', 'BIRTHS2010', 'BIRTHS2011', 'BIRTHS2012', 'BIRTHS2013', 'BIRTHS2014', 'BIRTHS2015', 'POPESTIMATE2010', 'POPESTIMATE2011', 'POPESTIMATE2012', 'POPESTIMATE2013', 'POPESTIMATE2014', 'POPESTIMATE2015']

df = df[columns]
print(df.head())

# We can load the data and set the index to be a combination of the state and county values and see how pandas handles it in a DataFrame. We do this by creating a list of the column identifiers we want to have indexed. And then calling set index with this list and assigning the output as appropriate. We see here that we have a dual index, first the state name and second the county name.

df = df.set_index(['STNAME', 'CTYNAME'])
print(df.head())

# How we can query this DataFrame? .loc attribute can take multiple arguments, and it could query both the row and the columns. When you use a multi index you must provide the arguments in order by the level you wish to query. Inside if the index, each column is called a level and the outermost column is level zero.

# If we want to see the population results from Washtenaw County in Michigan, the first argument would be Michigan and the second one would be Washtenaw County.

print(df.loc['Michigan', 'Washtenaw County'])

# If we are interested in comparing two counties, we can pass a list of tuples describing the indices we wish to query into loc. Each tuple should have two elements, the first one being the first index and the second one being the second index.

# Therefore, in this case, we will have a list of two tuples, in each tuple, the first element is Michigan, and the second element is either Washtenaw County or Wayne County.

print( df.loc[ [('Michigan', 'Washtenaw County'), 
                ('Michigan', 'Wayne County')] ] )
